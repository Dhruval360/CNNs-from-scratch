{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6.9 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
        }
      }
    },
    "colab": {
      "name": "CNN-using-numpy.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC1REbgt6OB3"
      },
      "source": [
        "Author: Dhruval PB (https://github.com/Dhruval360/CNNs-from-scratch.git)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3-j2Irw6OCJ"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow # Used only for loading the dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKOQenXi6OCL"
      },
      "source": [
        "# Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvvALhx46OCL",
        "outputId": "6463122e-d8c0-4b2e-8fad-a3450128d379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tensorflow.keras.datasets.mnist.load_data()\n",
        "\n",
        "num = 10\n",
        "images = train_images[:num]\n",
        "labels = train_labels[:num]\n",
        "num_row = 2\n",
        "num_col = 5\n",
        "\n",
        "fig, axes = plt.subplots(num_row, num_col, figsize=(2*num_col,2*num_row))\n",
        "for i in range(num):\n",
        "    ax = axes[i//num_col, i%num_col]\n",
        "    ax.imshow(images[i], cmap='gray')\n",
        "    ax.set_title('Label: {}'.format(labels[i]))\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Train images shape: \", train_images.shape)\n",
        "print(\"Testing images shape: \", test_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXXmW-yV6OCM"
      },
      "source": [
        "# Convolution layer\n",
        "* This layer is used for feature extraction\n",
        "* Multiple filters are applied on the input to obtain different features\n",
        "* The size of the output after applying convolution is given by:\n",
        "\n",
        "$$O = \\frac{I - F + 2P}{S} + 1$$\n",
        "\n",
        "        Where,\n",
        "        O = Output size\n",
        "        I = Input size\n",
        "        F = Filter size\n",
        "        S = Stride\n",
        "        P = Padding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMY82g7H6OCN"
      },
      "source": [
        "class Conv2D:\n",
        "    def __init__(self, input_shape, num_filters, filter_size, stride, padding = 0):\n",
        "        self.output_shape = (int(input_shape[0] - filter_size[0] + 2*padding)//stride + 1, int(input_shape[1] - filter_size[1] + 2*padding)//stride + 1, num_filters)\n",
        "\n",
        "        # Hyperparameters\n",
        "        self.num_filters = num_filters\n",
        "        self.filter_size = filter_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "                \n",
        "        # Trainable parameter (weights of the filter)\n",
        "        self.conv_filter = np.random.normal(size = (num_filters, filter_size[0] , filter_size[1])) # Initialising the filters with random normalised floats\n",
        "    \n",
        "    def image_region(self, image): # A Generator function to extract patches of the image\n",
        "        height, width = image.shape\n",
        "        for j in range(0, height - self.filter_size[0] + 1, self.stride):\n",
        "            for k in range(0, width - self.filter_size[1] + 1, self.stride):\n",
        "                image_patch = image[j : (j + self.filter_size[0]), k : (k + self.filter_size[1])]\n",
        "                yield image_patch\n",
        "    \n",
        "    def pad(self, input):\n",
        "        output_shape = (input.shape[0] + 2*self.padding, input.shape[1] + 2*self.padding)\n",
        "        result = np.zeros(output_shape) \n",
        "        result[self.padding : (input.shape[0] + self.padding), self.padding : (input.shape[1] + self.padding)] = input\n",
        "        return result\n",
        "\n",
        "    def forward_prop(self, image): # Defining the convolution operation\n",
        "        self.image = self.pad(image)\n",
        "        height, width = self.image.shape\n",
        "        self.conv_out = np.zeros(((height - self.filter_size[0])//self.stride + 1, (width - self.filter_size[1])//self.stride + 1, self.num_filters)) \n",
        "\n",
        "        image_patch = self.image_region(self.image)\n",
        "        for i in range(self.conv_out.shape[0]):\n",
        "            for j in range(self.conv_out.shape[1]):\n",
        "                self.conv_out[i,j] = np.sum(next(image_patch) * self.conv_filter, axis = (1,2))\n",
        "        return self.conv_out\n",
        "    \n",
        "    def back_prop(self, dL_dout, learning_rate): # The differential dL/dout is obtained from the max pooling layer\n",
        "        dL_dF_params = np.zeros(self.conv_filter.shape)\n",
        "        \n",
        "        image_patch = self.image_region(self.image)\n",
        "        for i in range(self.conv_out.shape[0]):\n",
        "            for j in range(self.conv_out.shape[1]):\n",
        "                patch = next(image_patch)\n",
        "                for k in range(self.num_filters):\n",
        "                    dL_dF_params[k] += patch * dL_dout[i,j,k]\n",
        "        \n",
        "        # Update the filter weights\n",
        "        self.conv_filter -= learning_rate * dL_dF_params\n",
        "        return dL_dF_params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNfQpsRG6OCP"
      },
      "source": [
        "# Maxpooling layer\n",
        "* The main function of this layer is to reduce the dimension of the input\n",
        "* It forwards only the most prominent parts of the input to the next layer (pixels with the highest value)\n",
        "* As some data is lost in this process, it is always better to use a maxpooling layer with a small filter size\n",
        "* This layer does not have any trainable parameters\n",
        "* The size of the output after applying maxpooling is given by:\n",
        "\n",
        "$$O = \\frac{I - F + 2P}{S} + 1$$\n",
        "\n",
        "        Where,\n",
        "        O = Output size\n",
        "        I = Input size\n",
        "        F = Filter size\n",
        "        S = Stride\n",
        "        P = Padding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFmeO3vQ6OCQ"
      },
      "source": [
        "class MaxPool:\n",
        "    def __init__(self, input_shape, filter_size, stride, padding = 0):\n",
        "        self.output_shape = ((input_shape[0] - filter_size[0] + 2*padding)//stride + 1, (input_shape[1] - filter_size[1] + 2*padding)//stride + 1, input_shape[2])\n",
        "\n",
        "        # Hyperparameters\n",
        "        self.filter_size = filter_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "    \n",
        "    def image_region(self, image): # A Generator function to extract patches of the image\n",
        "        height, width = image.shape[0], image.shape[1]\n",
        "        for j in range(0, height - self.filter_size[0] + 1, self.stride):\n",
        "            for k in range(0, width - self.filter_size[1] + 1, self.stride):\n",
        "                image_patch = image[j : (j + self.filter_size[0]), k : (k + self.filter_size[1])]\n",
        "                yield image_patch\n",
        "\n",
        "    def pad(self, input): # This pad function has to pad all the layers of the input\n",
        "        output_shape = (input.shape[0] + 2*self.padding, input.shape[1] + 2*self.padding, input.shape[2])\n",
        "        result = np.zeros(output_shape) \n",
        "        for i in range(input.shape[2]):\n",
        "            result[self.padding : (input.shape[0] + self.padding), self.padding : (input.shape[1] + self.padding), i] = input[:,:,i]\n",
        "        return result\n",
        "\n",
        "    def forward_prop(self, image): # Defining the MaxPooling operation\n",
        "        self.image = self.pad(image)        \n",
        "        height, width, num_filters = self.image.shape\n",
        "        \n",
        "        self.output = np.zeros(((height - self.filter_size[0])//self.stride + 1, (width - self.filter_size[1])//self.stride + 1, num_filters)) \n",
        "\n",
        "        image_patch = self.image_region(self.image)\n",
        "        for i in range(self.output.shape[0]):\n",
        "            for j in range(self.output.shape[1]):\n",
        "                self.output[i,j] = np.amax(next(image_patch), axis = (0,1))\n",
        "            \n",
        "        return self.output\n",
        "    \n",
        "\n",
        "    def back_prop(self, dL_dout, learning_rate): # This layer does not have any trainable parameters (no weights or biases)\n",
        "        dL_dmax_pool = np.zeros(self.image.shape)\n",
        "        image_patch = self.image_region(self.image)\n",
        "        for i in range(self.output.shape[0]):\n",
        "            for j in range(self.output.shape[1]):\n",
        "                patch = next(image_patch)\n",
        "                height, width, num_filters = patch.shape\n",
        "                maximum_val = np.amax(patch, axis = (0,1))\n",
        "                \n",
        "                for i1 in range(height):\n",
        "                    for j1 in range(width):\n",
        "                        for k1 in range(num_filters):\n",
        "                            if patch[i1, j1, k1] == maximum_val[k1]:\n",
        "                                dL_dmax_pool[i*self.filter_size[0] + i1, j*self.filter_size[1] + j1, k1] = dL_dout[i, j, k1]\n",
        "        return dL_dmax_pool"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MwgN41w6OCT"
      },
      "source": [
        "# Softmax layer\n",
        "* The softmax function is a function that turns a vector of K real values into a vector of K real values that sum to 1.\n",
        "* The input values can be positive, negative, zero, or greater than one, but the softmax transforms them into values between 0 and 1, so that they can be interpreted as probabilities. \n",
        "* If one of the inputs is small or negative, the softmax turns it into a small probability, and if an input is large, then it turns it into a large probability, but it will always remain between 0 and 1.\n",
        "* The softmax function is sometimes called the softargmax function, or multi-class logistic regression. This is because the softmax is a generalization of logistic regression that can be used for multi-class classification, and its formula is very similar to the sigmoid function which is used for logistic regression. \n",
        "* The softmax function can be used in a classifier only when the classes are mutually exclusive.\n",
        "* Many multi-layer neural networks end in a penultimate layer which outputs real-valued scores that are not conveniently scaled and which may be difficult to work with. Here the softmax is very useful because it converts the scores to a normalized probability distribution, which can be displayed to a user or used as input to other systems. For this reason it is usual to append a softmax function as the final layer of the neural network.\n",
        "* The softmax function is given by\n",
        "$$\\sigma(\\overrightarrow{Z})_{i} = \\frac{e^{Z_{i}}}{\\sum\\limits_{j=1}^{K}e^{Z_{j}}}$$\n",
        "\n",
        "Where,\n",
        "\n",
        "$\\overrightarrow{Z}$ = The input vector to the softmax function, made up of (z0, ... zK)\n",
        "\n",
        "$Z_{i}$ = All the zi values are the elements of the input vector to the softmax function, and they can take any real value, positive, zero or negative. For example a neural network could have output a vector such as (-0.62, 8.12, 2.53), which is not a valid probability distribution, hence why the softmax would be necessary.\n",
        "\t\n",
        "$e^{Z_{i}}$ = The standard exponential function is applied to each element of the input vector. This gives a positive value above 0, which will be very small if the input was negative, and very large if the input was large. However, it is still not fixed in the range (0, 1) which is what is required of a probability.\n",
        "\t\n",
        "$\\sum\\limits_{j=1}^{K}e^{Z_{j}}$ = The term on the bottom of the formula is the normalization term. It ensures that all the output values of the function will sum to 1 and each be in the range (0, 1), thus constituting a valid probability distribution.\n",
        "\t\n",
        "K = The number of classes in the multi-class classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A37TNSL96OCU"
      },
      "source": [
        "class Softmax:\n",
        "    def __init__(self, input_node, softmax_node):\n",
        "        input_node = int(input_node)\n",
        "        self.weight = np.random.randn(input_node, softmax_node) / input_node\n",
        "        self.bias = np.zeros(softmax_node)\n",
        "    \n",
        "    def forward_prop(self, image):\n",
        "        self.orig_im_shape = image.shape # Used in backprop\n",
        "        image_modified = image.flatten()\n",
        "        self.modified_input = image_modified # To be used in backprop\n",
        "        output_val = np.dot(image_modified, self.weight) + self.bias\n",
        "        self.out = output_val\n",
        "        exp_out = np.exp(output_val)\n",
        "        return exp_out/np.sum(exp_out, axis = 0) # Probability output\n",
        "    \n",
        "    def back_prop(self, dL_dout, learning_rate):\n",
        "        for i, grad in enumerate(dL_dout):\n",
        "            if grad == 0:\n",
        "                continue\n",
        "            \n",
        "            transformation_eq = np.exp(self.out)\n",
        "            S_total = np.sum(transformation_eq)\n",
        "\n",
        "            # Gradients with respect to out (z)\n",
        "            dy_dz = -transformation_eq[i] * transformation_eq / (S_total** 2)\n",
        "            dy_dz[i] = transformation_eq[i]*(S_total - transformation_eq[i]) / (S_total**2)\n",
        "\n",
        "            # Gradients of totals against weights/biases/input\n",
        "            dz_dw = self.modified_input\n",
        "            dz_db = 1\n",
        "            dz_d_inp = self.weight\n",
        "\n",
        "            # Gradients of loss against totals\n",
        "            dL_dz = grad * dy_dz\n",
        "\n",
        "            # Gradients of loss against weights/biases/input\n",
        "            dL_dw = dz_dw[np.newaxis].T @ dL_dz[np.newaxis]\n",
        "            dL_db = dL_dz * dz_db\n",
        "            dL_d_inp = dz_d_inp @ dL_dz\n",
        "\n",
        "        # Update weights and biases\n",
        "        self.weight -= learning_rate * dL_dw\n",
        "        self.bias -= learning_rate * dL_db\n",
        "        return dL_d_inp.reshape(self.orig_im_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu_tyaNd6OCV"
      },
      "source": [
        "# Example outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqD39Rg-6OCW",
        "outputId": "792bea67-3b14-4e27-9cff-024c38f179a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "index = 7\n",
        "image_in = images[index]\n",
        "label = labels[index]\n",
        "num_col = 10\n",
        "num_row = 2\n",
        "num = 10\n",
        "\n",
        "layer1 = Conv2D(image_in.shape, 10, (3,3), stride = 2, padding = 0) # A convolutional layer with 10 filters, each of size 3x3\n",
        "layer2 = MaxPool(layer1.output_shape, (3,3), stride = 3, padding = 0)   # A Max pooling layer with filter size 3x3\n",
        "layer3 = Softmax(np.prod(layer2.output_shape, axis=None), 10) # Softmax layer\n",
        "\n",
        "t1 = time.time()\n",
        "output1 = layer1.forward_prop(image_in) # Applying the Convolution\n",
        "t2 = time.time()\n",
        "print(\"Time taken for Convolution layer = \", t2-t1, \"s\")\n",
        "\n",
        "t1 = time.time()\n",
        "output2 = layer2.forward_prop(output1) # Applying Max Pooling\n",
        "t2 = time.time()\n",
        "print(\"Time taken for MaxPooling layer = \", t2-t1, \"s\")\n",
        "\n",
        "t1 = time.time()\n",
        "output3 = layer3.forward_prop(output2) # Applying Softmax\n",
        "t2 = time.time()\n",
        "print(\"Time taken for Softmax layer = \", t2-t1, \"s\")\n",
        "\n",
        "fig, axes = plt.subplots(num_row, num_col, figsize=(2*num_col,2*num_row))\n",
        "for i in range(num):\n",
        "    ax = axes[0, i]\n",
        "    ax.imshow(output1[:,:,i], cmap='gray')\n",
        "    ax.set_title('Label: {}'.format(labels[index]))\n",
        "\n",
        "    ax = axes[1, i]\n",
        "    ax.imshow(output2[:,:,i], cmap='gray')\n",
        "    ax.set_title('Label: {}'.format(labels[index]))\n",
        "    \n",
        "axes[0, 0].set_ylabel(\"Convolution output\", rotation=90, size='large')\n",
        "axes[1, 0].set_ylabel(\"MaxPooling output\", rotation=90, size='large')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Softmax output: \", output3)\n",
        "print(\"\\nPrediction: \", np.argmax(output3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVOzlmdn6OCX"
      },
      "source": [
        "# Defining the model and writing wrapper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYXLSVR66OCX"
      },
      "source": [
        "# Model\n",
        "conv = Conv2D((train_images.shape[1], train_images.shape[2]), 8, (2,2), stride = 2, padding = 1)\n",
        "pool = MaxPool(conv.output_shape, (2,2), stride = 2, padding = 1)\n",
        "softmax = Softmax(np.prod(pool.output_shape, axis=None), 10)\n",
        "\n",
        "model = [conv, pool, softmax]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8mZRUlt6OCX"
      },
      "source": [
        "# A wrapper function that does only forward propagation \n",
        "def cnn_forward_prop(image, label, layers):\n",
        "    out_p = (image/255) - 0.5\n",
        "    for i in layers:\n",
        "      out_p = i.forward_prop(out_p)\n",
        "\n",
        "    # Calculating cross-entropy loss and accuracy\n",
        "    cross_ent_loss = -np.log(out_p[label])\n",
        "    accuracy_eval = 1 if np.argmax(out_p) == label else 0\n",
        "\n",
        "    return out_p, cross_ent_loss, accuracy_eval\n",
        "\n",
        "# A wrapper function that does both forward and backward propagation (training)\n",
        "def training_cnn(image, labl, layers, learn_rate = 0.005):\n",
        "    # Forward Prop\n",
        "    out, loss, acc = cnn_forward_prop(image, label, layers)\n",
        "\n",
        "    # Calculate initial gradient\n",
        "    gradient = np.zeros(10)\n",
        "    gradient[label] = -1/out[label]\n",
        "\n",
        "    # Backprop\n",
        "    grad_back = gradient\n",
        "    for i in layers[::-1]:\n",
        "      grad_back = i.back_prop(grad_back, learn_rate)\n",
        "\n",
        "    return loss, acc\n",
        "\n",
        "# A wrapper function that does only prediction \n",
        "def cnn_predict(image, layers):\n",
        "    out_p = (image/255) - 0.5\n",
        "    for i in layers:\n",
        "      out_p = i.forward_prop(out_p)\n",
        "    return np.argmax(out_p)\n",
        "\n",
        "# A wrapper function that does only prediction and shows the outputs of the intermediate steps\n",
        "def cnn_predict_show_inner_workings(image, layers):\n",
        "    out_p = (image/255) - 0.5\n",
        "    outputs = []\n",
        "    for i in layers:\n",
        "      out_p = i.forward_prop(out_p)\n",
        "      outputs.append(out_p)\n",
        "\n",
        "    plots = []\n",
        "    layer = 1\n",
        "    for output in outputs[:-1:]:\n",
        "      fig, axes = plt.subplots(1, output.shape[-1], figsize=(2*output.shape[-1],2))\n",
        "      axes[0].set_ylabel(f\"Layer {layer} output\", rotation=90, size='large')\n",
        "      for i in range(output.shape[-1]):\n",
        "          ax = axes[i]\n",
        "          ax.imshow(output[:,:,i], cmap='gray')\n",
        "      layer += 1\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(\"Softmax layer output: \", outputs[-1])\n",
        "    return np.argmax(outputs[-1])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPwcvHuo6OCY"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwAWpKmV6OCY",
        "outputId": "973a3b17-649d-41a1-a5f6-6095b8091bcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = {\"Accuracy\":[0], \"Average Loss\":[0], \"TimePerStep\":0}\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('\\nEpoch %d --->' %(epoch + 1))\n",
        "\n",
        "    # Shuffle the training data\n",
        "    shuffle_data = np.random.permutation(len(train_images))\n",
        "    train_images = train_images[shuffle_data]\n",
        "    train_labels = train_labels[shuffle_data]\n",
        "    x = train_images[:1000]\n",
        "    y = train_labels[:1000]\n",
        "    training_data = zip(x, y)\n",
        "\n",
        "    # Training the CNN\n",
        "    loss = history[\"Average Loss\"][epoch]\n",
        "    num_correct = history['Accuracy'][epoch]\n",
        "    t1 = time.time()\n",
        "    for i, (im, label) in enumerate(training_data):\n",
        "        if i % 100 == 0:\n",
        "            loss /= 100\n",
        "            history[\"TimePerStep\"] = (time.time()-t1)/100\n",
        "            print('Step %d: Average Loss %.3f and Accuracy: %d%% || Time per step = %.3f seconds' %(i+1, loss, num_correct, history[\"TimePerStep\"]))\n",
        "            loss = num_correct = 0\n",
        "            t1 = time.time()\n",
        "        l1, accu = training_cnn(im, label, model)\n",
        "        loss += l1\n",
        "        num_correct += accu\n",
        "    history[\"Accuracy\"].append(num_correct)\n",
        "    history[\"Average Loss\"].append(loss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqwXeAdL6OCZ"
      },
      "source": [
        "# Graphing the model's training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWMtEpNY6OCZ",
        "outputId": "56ec763a-caf3-43e9-ec0a-aa09226f7f2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(range(epochs + 1),history[\"Accuracy\"])\n",
        "plt.plot(range(epochs + 1),history[\"Average Loss\"])\n",
        "\n",
        "plt.legend([\"Accuracy\", \"Average Loss\"])\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "\n",
        "plt.title(\"Variation of Training Accuracy and Average Loss with number of epochs\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk5GdK4c6OCZ"
      },
      "source": [
        "# Evaluating the model on the Testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQoSVaOX6OCZ",
        "outputId": "fd660a56-90d3-42ae-cdd3-4c9f902c86f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t1 = time.time()\n",
        "num_correct = 0\n",
        "test_images = test_images[:5000]\n",
        "test_labels = test_labels[:5000]\n",
        "test_data = zip(test_images, test_labels)\n",
        "for i, (im, label) in enumerate(test_data):\n",
        "    prediction = cnn_predict(im, model)\n",
        "    if label == prediction:\n",
        "        num_correct += 1\n",
        "t2 = time.time()\n",
        "print(f\"Time taken for predicting {len(test_images)} pictures is {t2-t1} s\")\n",
        "print(\"Testing accuracy = \", num_correct/len(test_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "An3JPVcB6OCa"
      },
      "source": [
        "# Showing the intermidiate steps involved during prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgZGyAbT6OCa",
        "outputId": "347b1b8b-5e39-48f0-c58b-f36e50bfd5e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "prediction = cnn_predict_show_inner_workings(test_images[1335], model)\n",
        "print(\"Prediction = \", prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3h9C5FX6OCa",
        "outputId": "270fc357-d97f-450c-dd42-32aa593f4721",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "prediction = cnn_predict_show_inner_workings(test_images[1200], model)\n",
        "print(\"Prediction = \", prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpXkptQt_KZk"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}